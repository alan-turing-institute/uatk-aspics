{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef48166",
   "metadata": {},
   "source": [
    "# Calibration of multiple parameters for ASPICS model, using ABC method\n",
    "\n",
    "This jupyter notebook is based on the previous efforts from DyME and Prof Nick Malleson (University of Leeds)\n",
    "\n",
    "- [RAMP-UA Initiative](https://github.com/Urban-Analytics/RAMP-UA/blob/d5973dff007645f1700cded93aaf72298ef84c61/experiments/calibration/abc-1.ipynb)\n",
    "\n",
    "- [Calibrating Agent-Based Models Using Uncertainty Quantification Methods](https://github.com/Urban-Analytics/uncertainty/blob/master/hm_abc_simple_example.ipyn)\n",
    "\n",
    "As SPC (Synthetic Population Catalyst) is a tool that helps urban modelling researchers to get synthetic population datasets at national level (currently limitated to England). This tool opens up new challenges/possibilities where external models (multi-level) like Agent-based models -ABM now can be tested in multi regions. However in models with location parameters striclty dependend on the population interactions, internal validation and calibrations process are seen as a relevant and requiered to properly tune this national behaivor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e790da",
   "metadata": {},
   "source": [
    "### ToDO to make progress in this experiment\n",
    "- [] Read the Synt Pop file - Translate to snaphot then ASPICS can read the new dataset.\n",
    "- [] Read and plot the attributes we need, we could plot\n",
    "- [] Read the baseline use as priors - Areas to test Leeds ( ideally West Yorkshire), Liverpool, Devon, Manchester (Grand Manchester)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db61a3a",
   "metadata": {},
   "source": [
    "## Background Concepts\n",
    "\n",
    "- Uncertanity of ABM\n",
    "- Methods for Calibration\n",
    "- ABC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1084c0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from run_model import OpenCLRunner\n",
    "\n",
    "sys.path.append('../')\n",
    "import synthpop_pb2\n",
    "import convert_snapshot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc56c3e",
   "metadata": {},
   "source": [
    "The following function is based on [SPC scripts](https://github.com/alan-turing-institute/uatk-spc/blob/main/python/protobuf_to_csv.py) the idea is to read the .pb file created with the tool. However we need to make a translation from the proto file to snapshot which will integarte the data in the way ASPICS need it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c428ea0",
   "metadata": {},
   "source": [
    "```\n",
    "def convert_to_csv(input_path):\n",
    "    \"\"\"Export some per-person attributes to CSV.\"\"\"\n",
    "    # Parse the .pb file\n",
    "    print(f\"Reading {input_path}\")\n",
    "    pop = synthpop_pb2.Population()\n",
    "    f = open(input_path, \"rb\")\n",
    "    pop.ParseFromString(f.read())\n",
    "    f.close()\n",
    "\n",
    "    # Based on the per-person information you're interested in, you can extract\n",
    "    # and fill out different columns\n",
    "    people = []\n",
    "    for person in pop.people:\n",
    "        # The Person message doesn't directly store MSOA. Look up from their household.\n",
    "        msoa11cd = pop.households[person.household].msoa11cd\n",
    "\n",
    "        record = {\n",
    "            \"person_id\": person.id,\n",
    "            \"household_id\": person.household,\n",
    "            \"msoa11cd\": msoa11cd,\n",
    "            \"age_years\": person.demographics.age_years,\n",
    "            # Protobuf enum types show up as numbers; this converts to a string\n",
    "            \"pwkstat\": synthpop_pb2.PwkStat.Name(person.employment.pwkstat),\n",
    "            \"diabetes\": person.health.has_diabetes,\n",
    "            \"employment\": person.employment.sic1d07,\n",
    "        }\n",
    "\n",
    "        # Add a column for the duration the person spends doing each activity\n",
    "        for pair in person.activity_durations:\n",
    "            key = synthpop_pb2.Activity.Name(pair.activity) + \"_duration\"\n",
    "            record[key] = pair.duration\n",
    "\n",
    "        people.append(record)\n",
    "\n",
    "    df = pd.DataFrame.from_records(people)\n",
    "    return(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e190012",
   "metadata": {},
   "source": [
    "```\n",
    "## Reading the previous function\n",
    "input_path = 'SPC_data/rutland.pb'\n",
    "if __name__ == \"__main__\":\n",
    "    df = convert_to_csv(input_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b10051",
   "metadata": {},
   "source": [
    "## Read the baseline data. Defined as prior to calibrate the model to a given area\n",
    "Real observations (number of cases, deaths or hospital admission in the given area)\n",
    "They need to be made cumulative as this is how they will be compared to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e5f8e9",
   "metadata": {},
   "source": [
    "#### Rutland area as test run due it size\n",
    "The data for no of cases and the gam_cases data were created using [Ramp-UA - Observation Data](https://github.com/Urban-Analytics/RAMP-UA/tree/master/experiments/calibration/observation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f11f179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cases: 697\n"
     ]
    }
   ],
   "source": [
    "# New per day:\n",
    "gam_cases = pd.read_csv(os.path.join(\"baseline_data\", \"gam_rutland_cases.csv\"), header=0, names=[\"Day\", \"Cases\"], )\n",
    "\n",
    "# Cumulative\n",
    "OBSERVATIONS = pd.DataFrame( {\"Day\": gam_cases['Day'], \"Cases\": gam_cases.cumsum()['Cases']} )\n",
    "\n",
    "assert OBSERVATIONS.tail(1)['Cases'].values[0] == sum(gam_cases['Cases'])\n",
    "print(f\"Total cases: {sum(gam_cases['Cases'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d97cfca",
   "metadata": {},
   "source": [
    "## Run ASPIC using the default parameters\n",
    "\n",
    "The following cells provide a set of plots to define how the model run with the default parameeters ( manually calibrated for Devon area). In this example we use Rutland.\n",
    "\n",
    "Before everything we will need to translate the .pg file to the snapshot requeried by ASPCIS [Usage guide](docs/usage_guide.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e42932c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading SPC_data/rutland.pb\n",
      "Code block took: 0.14636 s\n",
      "Removing 6029 people from 70 households because the household has > 10 people\n",
      "Collapsing flows for 33446 people\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33446/33446 [00:01<00:00, 24826.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code block took: 1.35073 s\n",
      "Finalizing all coordinates\n",
      "Code block took: 0.07968 s\n",
      "Creating snapshot\n",
      "Code block took: 0.26521 s\n",
      "Wrote ../data/snapshots/Rutland/cache.npz\n"
     ]
    }
   ],
   "source": [
    "%run ../convert_snapshot.py -i SPC_data/rutland.pb -o ../data/snapshots/Rutland/cache.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca9e7b2",
   "metadata": {},
   "source": [
    "Great now we have the cache.npz in `data/snapshots`, go and take a quick look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "421ec630",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae9bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETERS_FILE = os.path.join(\"../../\",\"model_parameters\", \"default.yml\")\n",
    "PARAMS = OpenCLRunner.create_parameters(parameters_file=PARAMETERS_FILE)\n",
    "OPENCL_DIR = \"../../microsim/opencl\"\n",
    "SNAPSHOT_FILEPATH = os.path.join(OPENCL_DIR, \"snapshots\", \"cache.npz\")\n",
    "assert os.path.isfile(SNAPSHOT_FILEPATH), f\"Snapshot doesn't exist: {SNAPSHOT_FILEPATH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2727dea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ITERATIONS = 10  # Number of iterations to run for ( Initially suggestes as 100)\n",
    "NUM_SEED_DAYS = 10  # Number of days to seed the population\n",
    "USE_GPU = False\n",
    "STORE_DETAILED_COUNTS = False\n",
    "REPETITIONS = 2 #Initially suggested as 5\n",
    "\n",
    "assert ITERATIONS < len(OBSERVATIONS), \\\n",
    "    f\"Have more iterations ({ITERATIONS}) than observations ({len(OBSERVATIONS)}).\"\n",
    "\n",
    "# Initialise the class so that its ready to run the model.\n",
    "# This isn't actually necessary immediately as the `run_opencl_model_multi` function is a static method\n",
    "# so doesn't read any of the class parameters, but the init is necessary\n",
    "# for calibration later when some parameters can't be passed to the run function directly\n",
    "OpenCLRunner.init(\n",
    "    iterations = ITERATIONS, \n",
    "    repetitions = REPETITIONS, \n",
    "    observations = OBSERVATIONS,\n",
    "    use_gpu = USE_GPU,\n",
    "    store_detailed_counts = STORE_DETAILED_COUNTS, \n",
    "    parameters_file = PARAMETERS_FILE, \n",
    "    opencl_dir = OPENCL_DIR, \n",
    "    snapshot_filepath = SNAPSHOT_FILEPATH,\n",
    "    use_healthier_pop = False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('aspics')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ebb45998d057cd9337571d6794a119feabba8ecfd1819e0e1dec5f8d9581edaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
