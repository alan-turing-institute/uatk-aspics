{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef48166",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Calibration of multiple parameters for ASPICS model, using ABC method\n",
    "\n",
    "This jupyter notebook is based on the previous efforts from DyME and Prof Nick Malleson (University of Leeds)\n",
    "\n",
    "- [RAMP-UA Initiative](https://github.com/Urban-Analytics/RAMP-UA/blob/d5973dff007645f1700cded93aaf72298ef84c61/experiments/calibration/abc-1.ipynb)\n",
    "\n",
    "- [Calibrating Agent-Based Models Using Uncertainty Quantification Methods](https://github.com/Urban-Analytics/uncertainty/blob/master/hm_abc_simple_example.ipyn)\n",
    "\n",
    "As SPC (Synthetic Population Catalyst) is a tool that helps urban modelling researchers to get synthetic population datasets at national level (currently limitated to England). This tool opens up new challenges/possibilities where external models (multi-level) like Agent-based models -ABM now can be tested in multi regions. However in models with location parameters striclty dependend on the population interactions, internal validation and calibrations process are seen as a relevant and requiered to properly tune this national behaivor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e790da",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ToDO to make progress in this experiment\n",
    "- [X] Read the Synt Pop file - Translate to snaphot then ASPICS can read the new dataset.\n",
    "- [] Read and plot the attributes we need, we could plot\n",
    "- [] Read the baseline use as priors - Areas to test Leeds ( ideally West Yorkshire), Liverpool, Devon, Manchester (Grand Manchester)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db61a3a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Background Concepts\n",
    "\n",
    "- Uncertanity of ABM\n",
    "- Methods for Calibration\n",
    "- ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1084c0b9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from yaml import load, SafeLoader\n",
    "sys.path.append('../')\n",
    "from run_aspics import OpenCLRunner\n",
    "from aspics.disease_statuses import DiseaseStatus\n",
    "from aspics.loader import setup_sim\n",
    "from headless import run_headless\n",
    "import synthpop_pb2\n",
    "import convert_snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc56c3e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following function is based on [SPC scripts](https://github.com/alan-turing-institute/uatk-spc/blob/main/python/protobuf_to_csv.py) the idea is to read the .pb file created with the tool. However, we need to make a translation from the proto file to snapshot which will integarte the data in the way ASPICS need it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b10051",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Read the baseline data. Defined as prior to calibrate the model to a given area\n",
    "Real observations (number of cases, deaths or hospital admission in the given area)\n",
    "They need to be made cumulative as this is how they will be compared to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e5f8e9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Rutland area as test run due it size\n",
    "The data for no of cases and the gam_cases data were created using [Ramp-UA - Observation Data](https://github.com/Urban-Analytics/RAMP-UA/tree/master/experiments/calibration/observation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f11f179",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cases: 34166\n"
     ]
    }
   ],
   "source": [
    "# New per day:\n",
    "gam_cases = pd.read_csv(os.path.join(\"baseline_data\", \"gam_manchester_cases.csv\"), header=0, names=[\"Day\", \"Cases\"], )\n",
    "# Cumulative\n",
    "OBSERVATIONS = pd.DataFrame( {\"Day\": gam_cases['Day'], \"Cases\": gam_cases.cumsum()['Cases']} )\n",
    "assert OBSERVATIONS.tail(1)['Cases'].values[0] == sum(gam_cases['Cases'])\n",
    "print(f\"Total cases: {sum(gam_cases['Cases'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d97cfca",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run ASPIC using the default parameters\n",
    "\n",
    "The following cells provide a set of plots to define how the model run with the default parameters ( manually calibrated for Devon area). In this example we use Rutland.\n",
    "\n",
    "Before everything, we need to translate the .pb (protobufer) file to the snapshot required by ASPCIS [Usage guide](docs/usage_guide.md). You need to do this one time. Once you created your synthetic population file, then run 'run ../convert_snapshot.py -i SPC_data/{YOUR_NEW_AREA}.pb -o ../data/snapshots/{YOUR_NEW_AREA}/cache.npz'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Great now we have the cache.npz file in `data/snapshots`\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "os.chdir(\"../\") #Now we need to update the main directory then we can use aspics as the way was created."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a manually added parameters simulation based on {'microsim': {'study-area': 'Manchester', 'iterations': 80, 'use-lockdown': False, 'start-date': 10, 'output': True, 'output-every-iteration': False, 'repetitions': 1}, 'microsim_calibration': {'hazard_individual_multipliers': {'presymptomatic': 1.0, 'asymptomatic': 0.75, 'symptomatic': 1.0}, 'hazard_location_multipliers': {'Retail': 1.0, 'PrimarySchool': 1.0, 'SecondarySchool': 1.0, 'Home': 1.0, 'Work': 1.0}}, 'disease': {'current_risk_beta': 0.003}, 'health_conditions': {'sex': {'male_mortality': 1.0, 'male_symptomatic': 1.0, 'female_mortality': 1.0, 'female_symptomatic': 1.0}, 'type': {'cvd': 1, 'diabetes': 1, 'bloodpressure': 1, 'improve_health': False}, 'BMI': {'global_bmi': 1.0, 'white_Ethni_coff1': 5.7, 'white_Ethni_coff2': -0.3, 'white_Ethni_coff3': 0.0061, 'black_Ethni_coff1': 2.34, 'black_Ethni_coff2': -0.13, 'black_Ethni_coff3': 0.003, 'asian_Ethni_coff1': 9.407, 'asian_Ethni_coff2': -0.67, 'asian_Ethni_coff3': 0.014, 'other_Ethni_coff1': 9.21, 'other_Ethni_coff2': -0.646, 'other_Ethni_coff3': 0.012}, 'mortality_age': None, 'symptomatic_age': {'bin_size': 5, 'max_bin_idx': 18}, 'obesity': {'overweight': 1, 'obesity_40': 1.48, 'obesity_35': 1.48, 'obesity_30': 1.48}}}\n",
      "Loading snapshot from data/snapshots/Manchester/cache.npz\n",
      "Snapshot is 42 MB\n",
      "Snapshot.py caused an exception 'could not broadcast input array from shape (65,) into shape (52,)'. This can happen if the parameters in the model have changed after a snapshot has been created. Try deleting the snapshot file 'data/config/snapshots/cache.npz' and re-running the model.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (65,) into shape (52,)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(PARAMETERS_FILE, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m      3\u001B[0m     parameters \u001B[38;5;241m=\u001B[39m load(f, Loader\u001B[38;5;241m=\u001B[39mSafeLoader)\n\u001B[0;32m----> 5\u001B[0m simulator, snapshot, study_area, iterations \u001B[38;5;241m=\u001B[39m \u001B[43msetup_sim\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m#Initial configuration, based on the parameters to run the model\u001B[39;00m\n\u001B[1;32m      6\u001B[0m summary, final_state \u001B[38;5;241m=\u001B[39m run_headless(simulator, snapshot, iterations, quiet\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, store_detailed_counts\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/PycharmProjects/uatk-aspics/aspics/loader.py:63\u001B[0m, in \u001B[0;36msetup_sim\u001B[0;34m(parameters)\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;66;03m# set params\u001B[39;00m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m calibration_params \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m disease_params \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m health_conditions \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 63\u001B[0m     \u001B[43msnapshot\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcreate_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcalibration_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdisease_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhealth_conditions\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     64\u001B[0m     health_type \u001B[38;5;241m=\u001B[39m health_conditions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m health_type[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimprove_health\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m~/PycharmProjects/uatk-aspics/aspics/snapshot.py:47\u001B[0m, in \u001B[0;36mSnapshot.update_params\u001B[0;34m(self, new_params)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m     43\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSnapshot.py caused an exception \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. This can happen if the parameters in the model \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     44\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhave changed after a snapshot has been created. Try deleting the snapshot file \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     45\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/config/snapshots/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.npz\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m and re-running the model.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     46\u001B[0m     )\n\u001B[0;32m---> 47\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[0;32m~/PycharmProjects/uatk-aspics/aspics/snapshot.py:40\u001B[0m, in \u001B[0;36mSnapshot.update_params\u001B[0;34m(self, new_params)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate_params\u001B[39m(\u001B[38;5;28mself\u001B[39m, new_params):\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 40\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuffers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m new_params\u001B[38;5;241m.\u001B[39masarray()\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     42\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m     43\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSnapshot.py caused an exception \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. This can happen if the parameters in the model \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     44\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhave changed after a snapshot has been created. Try deleting the snapshot file \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     45\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/config/snapshots/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.npz\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m and re-running the model.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     46\u001B[0m         )\n",
      "\u001B[0;31mValueError\u001B[0m: could not broadcast input array from shape (65,) into shape (52,)"
     ]
    }
   ],
   "source": [
    "PARAMETERS_FILE = 'config/Rutland_Test.yml' # Reading the parameters file\n",
    "with open(PARAMETERS_FILE, \"r\") as f:\n",
    "    parameters = load(f, Loader=SafeLoader)\n",
    "\n",
    "simulator, snapshot, study_area, iterations = setup_sim(parameters)  #Initial configuration, based on the parameters to run the model\n",
    "summary, final_state = run_headless(simulator, snapshot, iterations, quiet=False, store_detailed_counts=True) #run the model in a headless mode"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run ASPICS using parameters manually defined.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PARAMETERS_FILE = 'config/Manchester.yml' # Reading the parameters file\n",
    "with open(PARAMETERS_FILE, \"r\") as f:\n",
    "    parameters = load(f, Loader=SafeLoader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calibration_params = parameters[\"microsim_calibration\"]\n",
    "disease_params = parameters[\"disease\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params_manual = OpenCLRunner.create_params_manually( parameters_file=PARAMETERS_FILE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "REPETITIONS = 5\n",
    "ITERATIONS = 100\n",
    "STUDY_AREA = \"Manchester\"\n",
    "OUTPUT = True\n",
    "OUTPUT_EVERY_ITERATION = False\n",
    "USE_LOCKDOWN = False\n",
    "START_DATE = 10\n",
    "#OBSERVATIONS IS DECLARED IN THE PREVIOUS CELL\n",
    "USE_GPU = True\n",
    "USE_HEALTHIER_POP = True\n",
    "STORE_DETAILED_COUNTS = True\n",
    "#PARAMETERS file IS DECLARED IN THE PREVIOUS CELL\n",
    "\n",
    "assert ITERATIONS < len(OBSERVATIONS), \\\n",
    "    f\"Have more iterations ({ITERATIONS}) than observations ({len(OBSERVATIONS)}).\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "OpenCLRunner.init(\n",
    "    iterations = ITERATIONS,\n",
    "    repetitions = REPETITIONS,\n",
    "    study_area= STUDY_AREA,\n",
    "    output=OUTPUT,\n",
    "    output_every_iteration=OUTPUT_EVERY_ITERATION,\n",
    "    use_lockdown=False,\n",
    "    start_date=START_DATE,\n",
    "    observations = OBSERVATIONS,\n",
    "    use_gpu = USE_GPU,\n",
    "    store_detailed_counts = STORE_DETAILED_COUNTS,\n",
    "    parameters_file = PARAMETERS_FILE,\n",
    "    use_healthier_pop = True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "OpenCLRunner.update(repetitions=10)  # Temporarily use more repetitions to give a good baseline, initially suggested as 10\n",
    "OpenCLRunner.update(store_detailed_counts=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(fitness0, sim0, obs0, out_params0, summaries0) = OpenCLRunner.run_aspics_with_params_abc({}, return_full_details=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39dc7a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "OpenCLRunner.update(repetitions=REPETITIONS)\n",
    "OpenCLRunner.update(store_detailed_counts=STORE_DETAILED_COUNTS)\n",
    "\n",
    "# Check the model returns the observations correctly\n",
    "np.array_equal(obs0, OBSERVATIONS.loc[:len(sim0)-1,\"Cases\"])\n",
    "\n",
    "# Print the fitness and plot the different disease counts\n",
    "print(f\"fitness: {fitness0}\")\n",
    "#print(pd.DataFrame({\"sim\":sim, \"real_obs1\":obs}))\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "x = range(len(sim0))\n",
    "ax.plot(x, OpenCLRunner.get_cumulative_new_infections(summaries0), label=\"sim\", color=\"orange\")\n",
    "ax.plot(x, obs0, label=\"obs\", color=\"blue\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_summaries(summaries, observations=None, plot_type=\"error_bars\"):\n",
    "\n",
    "    #fig, ax = plt.subplots(1, len(DiseaseStatus), sharey=True)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10,7))\n",
    "\n",
    "    # Work out the number of repetitions and iterations\n",
    "    iters, reps = _get_iters_and_reps(summaries)\n",
    "    x = range(iters)\n",
    "    total_not_susceptible = np.zeros(iters)  # Used to compare to observations\n",
    "\n",
    "    for d, disease_status in enumerate(DiseaseStatus):\n",
    "\n",
    "        # Calculate the mean and standard deviation\n",
    "        mean, sd = OpenCLRunner.get_mean_total_counts(summaries, d, get_sd=True)\n",
    "\n",
    "        # Don't plot susceptible or recovered as it hides everytihng else\n",
    "        if disease_status==DiseaseStatus.Susceptible or disease_status==DiseaseStatus.Recovered:\n",
    "            continue\n",
    "\n",
    "        if plot_type == \"error_bars\":\n",
    "            ax.errorbar(x, mean, sd, label=f\"{disease_status}\" )\n",
    "        elif plot_type == \"lines\":\n",
    "            for rep in range(reps):\n",
    "                ax.plot(x, matrix[rep], label=f\"{disease_status} {rep}\",\n",
    "                        color=plt.cm.get_cmap(\"hsv\", len(DiseaseStatus))(d) )\n",
    "\n",
    "    if observations is not None:\n",
    "        # Plot the observations (cumulative infections)\n",
    "        ax.plot(x, observations.loc[:len(x)-1, \"Cases\"],\n",
    "                label=f\"Observations (cumulative cases)\", color=\"black\", linestyle=\"dashed\")\n",
    "        # And the total new infections, for comparison\n",
    "        ax.plot(x, OpenCLRunner.get_cumulative_new_infections(summaries),\n",
    "               label=f\"Total not susceptible \", color=\"grey\", linestyle=\"dashed\")\n",
    "\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Disease Status\")\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.set_ylabel(\"Number of cases\")\n",
    "    #ax.set_ylim(0, 5000)\n",
    "    #ax.set_xlim(0,30)\n",
    "\n",
    "def _get_iters_and_reps(summaries):\n",
    "    reps = len(summaries)\n",
    "    iters = len(summaries[0].total_counts[0])\n",
    "    return (iters, reps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_summaries(summaries=summaries0, observations=OBSERVATIONS, plot_type=\"error_bars\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_disease_status_by_age(summaries):\n",
    "\n",
    "    #fig, ax = plt.subplots(1, len(DiseaseStatus), sharey=True)\n",
    "    fig, ax = plt.subplots(int(len(DiseaseStatus)/2), int(len(DiseaseStatus)/2),\n",
    "                           figsize=(15,11), tight_layout=True)\n",
    "    iters, reps = _get_iters_and_reps(summaries)\n",
    "    x = range(iters)\n",
    "    age_thresholds = summaries[0].age_thresholds\n",
    "\n",
    "    for d, disease_status in enumerate(DiseaseStatus):\n",
    "        lower_age_bound = 0\n",
    "        for age_idx in range(len(age_thresholds)):\n",
    "            matrix = np.zeros(shape=(reps, iters))\n",
    "            for rep in range(reps):\n",
    "                #matrix[age_idx][rep][it] = summaries[rep].age_counts[str(disease_status)][age_idx][it]\n",
    "                matrix[rep] = summaries[rep].age_counts[str(disease_status)][age_idx]\n",
    "            mean = np.mean(matrix, axis=0)\n",
    "            sd = np.std(matrix, axis=0)\n",
    "            ax.flat[d].errorbar(x, mean, sd, label=f\"{lower_age_bound} - {age_thresholds[age_idx]}\" )\n",
    "            lower_age_bound = age_thresholds[age_idx]\n",
    "\n",
    "            ax.flat[d].legend()\n",
    "            ax.flat[d].set_title(f\"{str(disease_status)}\")\n",
    "            ax.flat[d].set_xlabel(\"Iteration\")\n",
    "            ax.flat[d].set_ylabel(\"Number of cases\")\n",
    "    #fig.set_title(f\"Num {disease_status} people by age group\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_disease_status_by_age(summaries0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ABC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pyabc\n",
    "from pygam import LinearGAM  # For graphing posteriors\n",
    "from pyabc.transition.multivariatenormal import MultivariateNormalTransition  # For drawing from the posterior\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def distance(sim,obs):\n",
    "    fit = OpenCLRunner.fit_l2(sim[\"data\"],obs[\"data\"])\n",
    "    print(fit)\n",
    "    return fit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The following should all be constant (overiding whatever is in the default.yml parameters file)\n",
    "OpenCLRunner.set_constants( {\"home\": 1.0, \"presymptomatic\": 1.0, \"asymptomatic\": 1.0 })\n",
    "# FYI this is how to represent with discrete discributions and one possible value (hack that didn't work):\n",
    "current_risk_beta_rv = current_risk_beta_rv = pyabc.RV(\"norm\", 0.1, 0.155)\n",
    "\n",
    "# School and retail are all uniform between 0-1\n",
    "retail_rv, primary_school_rv, secondary_school_rv = ( pyabc.RV(\"uniform\", 0, 1) for _ in range(3)  )\n",
    "# Work needs some dampening because we know that workplaces are too big in the current implementation\n",
    "work_rv = pyabc.RV(\"beta\", 0.1, 2)\n",
    "\n",
    "# Individual multipliers (see justification at the start of this notebook).\n",
    "# Asymptomatic is normal such that the middle 95% is the range [0.138, 0.75]\n",
    "symptomatic_rv = (pyabc.RV(\"norm\", 0.444, 0.155) for _ in range(3))\n",
    "\n",
    "# Group all random variables together and give them a string name (this is needed for the distribution later)\n",
    "all_rv = { \"retail\": retail_rv, \"primary_school\": primary_school_rv, \"secondary_school\": secondary_school_rv, \"work\": work_rv,\n",
    "           \"symptomatic\": symptomatic_rv,\n",
    "           \"current_risk_beta\":current_risk_beta_rv}\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12,8), sharex=True, sharey=True)\n",
    "x = np.linspace(0,2,49)  # (specified so that we have some whole numbers)\n",
    "marker = itertools.cycle((',', '+', '.', 'o', '*'))\n",
    "for i, variable in enumerate([retail_rv, primary_school_rv, secondary_school_rv, work_rv,\n",
    "                              ]):\n",
    "    var_name = [ k for k,v in locals().items() if v is variable][0]  # Hack to get the name of the variable\n",
    "    ax = axes.flatten()[i]\n",
    "    #ax.plot(x, pyabc.Distribution(param=variable).pdf({\"param\": x}), label = var_name, marker=next(marker), ms=3)\n",
    "    ax.plot(x, pyabc.Distribution(param=variable).pdf({\"param\": x}))\n",
    "    ax.set_title(var_name)\n",
    "    ax.axvline(x=1.0, ls='--', color=\"grey\", label=\"x=1\")\n",
    "\n",
    "#ax.legend()\n",
    "fig.suptitle(\"Priors\")\n",
    "fig.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Most priors can be passed straight to the distribution, except for 'asymptomatic' because it's normal\n",
    "# so needs to be decorated to stay above 0\n",
    "priors = pyabc.Distribution(\n",
    "    #home = home_rv,\n",
    "    retail = retail_rv,\n",
    "    primary_school = primary_school_rv,\n",
    "    secondary_school = secondary_school_rv,\n",
    "    work = work_rv,\n",
    "    #presymptomatic = presymptomatic_rv,\n",
    "    #symptomatic = symptomatic_rv,\n",
    "    asymptomatic = pyabc.LowerBoundDecorator(asymptomatic_rv, 0.0),\n",
    "    #current_risk_beta = current_risk_beta_rv\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "abc = pyabc.ABCSMC(\n",
    "    models=OpenCLRunner.run_aspics_with_params_abc, # Model (could be a list)\n",
    "    parameter_priors=priors, # Priors (could be a list)\n",
    "    distance_function=distance,  # Distance function\n",
    "    sampler = pyabc.sampler.SingleCoreSampler()  # Single core because the model is parallelised\n",
    "    #transition=transition,  # Define how to transition from one population to the next\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_observed = OBSERVATIONS.loc[:ITERATIONS-1, \"Cases\"].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "db_path = (\"sqlite:///\" + os.path.join(\".\", \"abc-manchester.db\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_id = abc.new(db_path, {\"data\": y_observed})  # (ID only matters if multiple runs stored is same DB)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LOAD_PICKLES = True\n",
    "history = None\n",
    "fname = \"abc-manchester.pkl\"\n",
    "\n",
    "if LOAD_PICKLES and os.path.isfile(fname):\n",
    "    with open( fname, \"rb\" ) as f:\n",
    "        history = pickle.load(f)\n",
    "else:\n",
    "    history = abc.run(max_nr_populations=2)\n",
    "    # The history object only works if it has the associated database too ('abc-1.db')\n",
    "    with open( fname, \"wb\" ) as f:\n",
    "        pickle.dump( history, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for t in range(history.max_t + 1):\n",
    "    df, w = history.get_distribution(m=0, t=t)\n",
    "    pyabc.visualization.plot_kde_1d(df, w,x=\"asymptomatic\", ax=ax,label=\"PDF t={}\".format(t))\n",
    "#ax.axvline(y_observed, color=\"k\", linestyle=\"dashed\");\n",
    "ax.axvline(x=0.53, color=\"grey\", linestyle=\"dashed\");\n",
    "ax.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, arr_ax = plt.subplots(2, 2)\n",
    "\n",
    "pyabc.visualization.plot_sample_numbers(history, ax=arr_ax[0][0])\n",
    "pyabc.visualization.plot_epsilons(history, ax=arr_ax[0][1])\n",
    "#pyabc.visualization.plot_credible_intervals(\n",
    "#    history, levels=[0.95, 0.9, 0.5], ts=[0, 1, 2, 3, 4],\n",
    "#    show_mean=True, show_kde_max_1d=True,\n",
    "#    refval={'mean': 2.5},\n",
    "#    arr_ax=arr_ax[1][0])\n",
    "pyabc.visualization.plot_effective_sample_sizes(history, ax=arr_ax[1][1])\n",
    "\n",
    "plt.gcf().set_size_inches((12, 8))\n",
    "plt.gcf().tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,int(len(priors)/2), figsize=(12,10))\n",
    "\n",
    "#cmap = { 0:'k',1:'b',2:'y',3:'g',4:'r' }  # Do this automatically for len(params)\n",
    "\n",
    "for i, param in enumerate(priors.keys()):\n",
    "    ax = axes.flat[i]\n",
    "    for t in range(history.max_t + 1):\n",
    "        df, w = history.get_distribution(m=0, t=t)\n",
    "        pyabc.visualization.plot_kde_1d(df, w, x=param, ax=ax,\n",
    "                                        label=f\"{param} PDF t={t}\",\n",
    "                                        alpha=1.0 if t==0 else float(t)/history.max_t, # Make earlier populations transparent\n",
    "                                        color= \"black\" if t==history.max_t else None # Make the last one black\n",
    "                                        )\n",
    "        if param!=\"work\":\n",
    "            ax.set_xlim(0,1)\n",
    "        ax.legend(fontsize=\"small\")\n",
    "        #ax.axvline(x=posterior_df.loc[1,param], color=\"grey\", linestyle=\"dashed\")\n",
    "        #ax.set_title(f\"{param}: {posterior_df.loc[0,param]}\")\n",
    "        ax.set_title(f\"{param}\")\n",
    "fig.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# As above but only show two parameters (for a Turing presentation)\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,6))\n",
    "\n",
    "#cmap = { 0:'k',1:'b',2:'y',3:'g',4:'r' }  # Do this automatically for len(params)\n",
    "\n",
    "for i, param in enumerate(['primary_school', 'asymptomatic']):\n",
    "    ax = axes.flat[i]\n",
    "    t = history.max_t\n",
    "    df, w = history.get_distribution(m=0, t=t)\n",
    "    pyabc.visualization.plot_kde_1d(df, w, x=param, ax=ax,\n",
    "                                    label=f\"{param} PDF t={t}\",\n",
    "                                    alpha=1.0 if t==0 else float(t)/history.max_t, # Make earlier populations transparent\n",
    "                                    color= \"black\" if t==history.max_t else None # Make the last one black\n",
    "                                    )\n",
    "    if param!=\"work\":\n",
    "        ax.set_xlim(0,1)\n",
    "    ax.legend(fontsize=\"small\")\n",
    "    ax.set_title(f\"{param}\")\n",
    "fig.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,int(history.max_t/2), figsize=(10,8))\n",
    "for t in range(history.max_t + 1):\n",
    "   ax = axes.flat[t]\n",
    "   for i, param in enumerate(priors.keys()):\n",
    "       df, w = history.get_distribution(m=0, t=t)\n",
    "       pyabc.visualization.plot_kde_1d(df, w, x=param, ax=ax,\n",
    "           label=f\"{param}\")\n",
    "   ax.legend()\n",
    "   ax.set_title(f\"t={t}\")\n",
    "fig.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pyabc.visualization.plot_histogram_matrix(history, size=(12,10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Posterior"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_df, _w = history.get_distribution(m=0, t=history.max_t)\n",
    "# Merge dataframe and weights and sort by weight (highest weight at the top)\n",
    "_df['weight'] = _w\n",
    "posterior_df = _df.sort_values('weight', ascending=False).reset_index()\n",
    "posterior_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N_samples = 50\n",
    "df, w = history.get_distribution(m=0, t=history.max_t)\n",
    "\n",
    "# Sample from the dataframe of posteriors using KDE\n",
    "kde = MultivariateNormalTransition(scaling=1)\n",
    "kde.fit(df, w)\n",
    "samples = kde.rvs(N_samples)\n",
    "\n",
    "## Instead sample just using the weights (this isn't the best way to do it though, should use KDE)\n",
    "#df = df.reset_index()  # So that the row index is 0-N (currently it's something else)\n",
    "#sample_idx = np.random.choice(\n",
    "#            a=range(history.get_nr_particles_per_population().values[-1]),\n",
    "#            size=N_samples, replace=True, p=w)\n",
    "#samples = df.iloc[sample_idx]\n",
    "\n",
    "# Now run N models and store the results of each one\n",
    "fitness_l = []  # Fitness values for each sample (model)\n",
    "sim_l = []  # The full simulation results\n",
    "obs_l = []  # Observations (should be the same for each sample)\n",
    "out_params_l = []  # The parameters objects used in each sample (all parameters in the model)\n",
    "out_calibrated_params_l = []  # The values of the specific calibrated parameters for the sample\n",
    "summaries_l = []  # The summaries objects\n",
    "\n",
    "negative_count = 0  # Count the number of negatives returned in the KDE posterior\n",
    "for i, sample in samples.iterrows():\n",
    "\n",
    "    # Check for negatives. If needed, resample\n",
    "    while (sample < 0).values.any():\n",
    "        print(\"Found negatives. Resampling\")\n",
    "        negative_count += 1\n",
    "        sample = kde.rvs()\n",
    "\n",
    "    # Create a dictionary with the parameters and their values for this sample\n",
    "    param_values = { param:sample[str(param)] for param in priors}\n",
    "\n",
    "    # Run the model\n",
    "    (_fitness, _sim, _obs, _out_params, _summaries) = \\\n",
    "          OpenCLRunner.run_aspics_with_params_abc(param_values, return_full_details=True)\n",
    "    print(f\"Fitness: {_fitness}.\")\n",
    "    #print(f\"Fitness: {_fitness}. Sample: {sample}\")\n",
    "\n",
    "    fitness_l.append(_fitness)\n",
    "    sim_l.append(_sim)\n",
    "    obs_l.append(_obs)\n",
    "    out_params_l.append(_out_params)\n",
    "    out_calibrated_params_l.append(param_values)\n",
    "    summaries_l.append(_summaries)\n",
    "\n",
    "print(f\"Finished sampling. Ignored {negative_count} negative samples.\")\n",
    "\n",
    "# Sanity check\n",
    "for i in range(len(obs_l)-1):\n",
    "    assert np.array_equal(obs_l[0], obs_l[i])\n",
    "\n",
    "\n",
    "# Save these because it took ages to sample\n",
    "def pickle_samples(mode, *arrays):\n",
    "    if mode==\"save\":\n",
    "        with open(\"abc-2-samples.pkl\", \"wb\") as f:\n",
    "            for x in arrays:\n",
    "                pickle.dump(x, f)\n",
    "        return\n",
    "    elif mode==\"load\":\n",
    "        with open(\"abc-2-samples.pkl\", \"rb\") as f:\n",
    "            fitness_l = pickle.load(f)\n",
    "            sim_l = pickle.load(f)\n",
    "            obs_l = pickle.load(f)\n",
    "            out_params_l = pickle.load(f)\n",
    "            out_calibrated_params_l = pickle.load(f)\n",
    "            summaries_l = pickle.load(f)\n",
    "        return( fitness_l, sim_l, obs_l, out_params_l, out_calibrated_params_l, summaries_l)\n",
    "    else:\n",
    "        raise Exception(f\"Unkonwn mode: {mode}\")\n",
    "\n",
    "pickle_samples('save', fitness_l, sim_l, obs_l, out_params_l, out_calibrated_params_l, summaries_l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ebb45998d057cd9337571d6794a119feabba8ecfd1819e0e1dec5f8d9581edaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}